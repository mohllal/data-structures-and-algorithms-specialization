# python3 (this comment tells the grading system at Coursera to use python3 rather than python2)

# Given a set of ğ‘› segments {[ğ‘0,ğ‘0],[ğ‘1,ğ‘1],...,[ğ‘ğ‘›âˆ’1,ğ‘ğ‘›âˆ’1]} with integer coordinates on a line, find the minimum number ğ‘š of points such that each segment contains at least one point. 
# That is, find a set of integers ğ‘‹ of the minimum size such that for any segment [ğ‘ğ‘–,ğ‘ğ‘–] there is a point ğ‘¥ âˆˆ ğ‘‹ such that ğ‘ğ‘– â‰¤ ğ‘¥ â‰¤ ğ‘ğ‘–.

def optimal_points(segments):
    points = []
    return points

if __name__ == '__main__':
    n = int(input())
    segments = []
    for i in range(n):
        ipt = input()
        segments.append(list(map(int, ipt.split())))
    segments.sort()
    res = optimal_points(segments)
    print(len(res))
    for x in res:
        print(x, end=' ')